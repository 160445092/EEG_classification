{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "conv2d_0.1.2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEddhdC2tOhpH23mt2RkqA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/160445092/EEG_classification/blob/main/conv2d_0_1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVpCCUINGdtk",
        "outputId": "37a862d5-8098-40ad-d489-d644a082e18c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import scipy.io as sio\n",
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import offsetbox\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
        "                     discriminant_analysis, random_projection)\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAw6dlpdvj6k"
      },
      "source": [
        "#ファイルの読み込み\n",
        "def import_data(every=False):\n",
        "    if every:\n",
        "        electrodes = 25\n",
        "    else:\n",
        "        electrodes = 22\n",
        "    X, y = [], []\n",
        "    drive_root_dir=\"./gdrive/My Drive/data\"\n",
        "    for i in range(9):\n",
        "        A01T = h5py.File(drive_root_dir + \"/A0\" + str(i + 1) + 'T_slice.mat', 'r')\n",
        "        X1 = np.copy(A01T['image'])\n",
        "        X.append(X1[:, :electrodes, :])\n",
        "        y1 = np.copy(A01T['type'])\n",
        "        y1 = y1[0, 0:X1.shape[0]:1]\n",
        "        y.append(np.asarray(y1, dtype=np.int32))\n",
        "\n",
        "    for subject in range(9):\n",
        "        delete_list = []\n",
        "        for trial in range(288):\n",
        "            if np.isnan(X[subject][trial, :, :]).sum() > 0:\n",
        "                delete_list.append(trial)\n",
        "        X[subject] = np.delete(X[subject], delete_list, 0)\n",
        "        y[subject] = np.delete(y[subject], delete_list)\n",
        "    y = [y[i] - np.min(y[i]) for i in range(len(y))]\n",
        "    return X, y\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01M_jdOcWaJk"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxYYMZUlwJCK"
      },
      "source": [
        "#データの変換\n",
        "def train_test_subject(X, y, train_all=True, standardize=True):\n",
        "\n",
        "    l = np.random.permutation(len(X[0]))\n",
        "    X_test = X[0][l[:100], :, :]\n",
        "    y_test = y[0][l[:100]]\n",
        "\n",
        "    if train_all:\n",
        "        X_train = np.concatenate((X[0][l[100:], :, :], X[1], X[2], X[3], X[4], X[5], X[6], X[7], X[8]))\n",
        "        y_train = np.concatenate((y[0][l[100:]], y[1], y[2], y[3], y[4], y[5], y[6], y[7], y[8]))\n",
        "\n",
        "    else:\n",
        "        X_train = X[0][l[100:], :, :]\n",
        "        y_train = y[0][l[100:]]\n",
        "\n",
        "    X_train_mean = X_train.mean(0)\n",
        "    X_train_var = np.sqrt(X_train.var(0))\n",
        "\n",
        "    if standardize:\n",
        "        X_train -= X_train_mean\n",
        "        X_train /= X_train_var\n",
        "        X_test -= X_train_mean\n",
        "        X_test /= X_train_var\n",
        "\n",
        "    X_train = np.transpose(X_train, (0, 2, 1))\n",
        "    X_test = np.transpose(X_test, (0, 2, 1))\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgLVoUTTwazz"
      },
      "source": [
        "X, y = import_data(every=False)\n",
        "X_train,X_test,y_train,y_test = train_test_subject(X, y)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cesZRj5cxPv0",
        "outputId": "83a83363-2ef8-40dc-b719-ba0ea28d4342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print ('Training/Valid data shape: {}'.format(X_train.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "#print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "#print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2458, 1000, 22)\n",
            "Test data shape: (100, 1000, 22)\n",
            "Training/Valid target shape: (2458,)\n",
            "Test target shape: (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9txCXsjFKDMh",
        "outputId": "a639101d-8d41-473d-beaa-cf13e0643208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "x_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1, X_train.shape[2])\n",
        "x_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1, X_test.shape[2])\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 4)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 4)\n",
        "print ('Training/Valid data shape: {}'.format(x_train.shape))\n",
        "print ('Test data shape: {}'.format(x_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2458, 1000, 1, 22)\n",
            "Test data shape: (100, 1000, 1, 22)\n",
            "Training/Valid target shape: (2458, 4)\n",
            "Test target shape: (100, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oMwCbrWc745"
      },
      "source": [
        "CNN\n",
        "Layer 1: 25 Conv2D filters: kernel_size = (10,1), stride = (1,1) $\\rightarrow$ ELU $\\rightarrow$ MaxPool: size=(3,1), stride = (3,1) $\\rightarrow$ Flatten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O-eaj96I1bn",
        "outputId": "42d1d76a-e0e3-4789-8160-3fccc5240751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras import regularizers as reg\n",
        "from keras.layers import Conv1D,Conv2D,MaxPooling1D,Flatten,Dense,Dropout,BatchNormalization, GRU, LSTM, RNN\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "learning_rate_list = [1e-4, 5e-4, 1e-3]\n",
        "model_list         = []\n",
        "cmax               = 0 \n",
        "\n",
        "for learning_rate in learning_rate_list:\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(1000,1,22))) \n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,1), strides = (3,1)))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=optimizer,\n",
        "                 metrics=['accuracy'])\n",
        "#    model.summary()\n",
        "    model.fit(x_train,\n",
        "             y_train,\n",
        "             batch_size=64,\n",
        "             epochs=50,\n",
        "             validation_data=(x_test, y_test), verbose=False)\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    if(score[1]>cmax):\n",
        "      cmax = score[1]\n",
        "      parameters =  learning_rate\n",
        "      model_max  = model\n",
        "    model_list.append(model)\n",
        "\n",
        "print (\"Optimal learning rate: \" +str(parameters) )\n",
        "\n",
        "score = model_max.evaluate(x_test, y_test, verbose=0)\n",
        "# Print test accuracy\n",
        "print('\\n', 'Validation accuracy overall w/o dropout bn:', score[1]) \n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal learning rate: 0.0005\n",
            "\n",
            " Validation accuracy overall w/o dropout bn: 0.44999998807907104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX25S0JmdMKa",
        "outputId": "2512a9ef-5363-486f-d35f-ddf425e5ed56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "dropout_rate_list  = [0.2, 0.5, 0.7]\n",
        "learning_rate_list = [1e-4, 5e-4, 1e-3]\n",
        "# dropout_rate_list  = [0.5]\n",
        "# learning_rate_list = [1e-3]\n",
        "model_list         = []\n",
        "cmax               =0 \n",
        "for dropout in dropout_rate_list:\n",
        "  for learning_rate in learning_rate_list:\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Must define the input shape in the first layer of the neural network\n",
        "    model.add(tf.keras.layers.Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(1000,1,22))) \n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,1), strides = (3,1)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(dropout))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,1), strides=(3,1)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(dropout))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,1), strides=(3,1)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(dropout))          \n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(3,1), strides=(3,1)))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(dropout))  \n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    # model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "    # model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=optimizer,\n",
        "                 metrics=['accuracy'])\n",
        "    #from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "    #checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
        "    model.fit(x_train,\n",
        "             y_train,\n",
        "             batch_size=64,\n",
        "             epochs=100,\n",
        "             validation_data=(x_test, y_test), verbose=False)\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    if(score[1]>cmax):\n",
        "      cmax = score[1]\n",
        "      parameters = [dropout, learning_rate]\n",
        "      model_max  = model\n",
        "    model_list.append(model)\n",
        "\n",
        "print (\"Optimal learning rate: \" +str(parameters[1]) +  \" Optimal dropout rate: \" +str(parameters[0]))\n",
        "score = model_max.evaluate(x_test, y_test, verbose=0)\n",
        "# Print test accuracy\n",
        "print('\\n', 'Test accuracy overall:', score[1])\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal learning rate: 0.0005 Optimal dropout rate: 0.5\n",
            "\n",
            " Test accuracy overall: 0.7099999785423279\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}